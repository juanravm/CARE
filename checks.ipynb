{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b19add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea2e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuanravm\u001b[0m (\u001b[33mjuanravm-vall-d-hebron-institute-of-oncology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/juanrafaelvalera@vhio.org/ondemand/CARE/wandb/run-20251213_174202-CARE-3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juanravm-vall-d-hebron-institute-of-oncology/CARE/runs/CARE-3' target=\"_blank\">CARE-3</a></strong> to <a href='https://wandb.ai/juanravm-vall-d-hebron-institute-of-oncology/CARE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juanravm-vall-d-hebron-institute-of-oncology/CARE' target=\"_blank\">https://wandb.ai/juanravm-vall-d-hebron-institute-of-oncology/CARE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juanravm-vall-d-hebron-institute-of-oncology/CARE/runs/CARE-3' target=\"_blank\">https://wandb.ai/juanravm-vall-d-hebron-institute-of-oncology/CARE/runs/CARE-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from src.architecture.models import make_class_models, make_risk_models\n",
    "from src.preproc.preproc_utils import FCBFSelector, ToCuPy\n",
    "from src.utils.utils import setup_hyperparameters\n",
    "\n",
    "# 0) Setup run hyperparameters and W&B run\n",
    "config_path = \"src/configs/config.yaml\"\n",
    "_, run = setup_hyperparameters(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87e8dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 125 samples\n"
     ]
    }
   ],
   "source": [
    "# 1) Loading data\n",
    "df = pd.read_csv(\"data/data_train.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Filtering variables with too many missing values\n",
    "na_frac = df.drop(columns=[\"risk_status\", \"dfs_status\", \"dfs_time\"]).isna().mean()\n",
    "keep = na_frac[na_frac <= 0.10].index.tolist()\n",
    "df = df.loc[:, keep + [\"risk_status\", \"dfs_status\", \"dfs_time\"]]\n",
    "\n",
    "# Removing samples with any missing value\n",
    "keep = df.drop(columns=[\"risk_status\", \"dfs_status\", \"dfs_time\"]).dropna().index.tolist()\n",
    "df = df.loc[keep, :]\n",
    "\n",
    "print(f\"Training with {df.shape[0]} samples\")\n",
    "\n",
    "y_class = df[\"risk_status\"].copy()\n",
    "y_event = df[\"dfs_status\"].copy()\n",
    "y_time = df[\"dfs_time\"].copy()\n",
    "X = df.drop(columns=[\"risk_status\", \"dfs_status\", \"dfs_time\", \"os_status\"])\n",
    "X_class = X.loc[y_class.notna(), :]\n",
    "y_class = y_class.loc[y_class.notna()]\n",
    "\n",
    "# 4) Selector for best features\n",
    "selector = FCBFSelector(mode=\"rank\", threshold=0.0, n_bins=2)\n",
    "\n",
    "# 5) Models and hyperparameters search\n",
    "class_models = make_class_models()\n",
    "risk_models = make_risk_models()\n",
    "\n",
    "cv_class = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scorer_class = make_scorer(roc_auc_score)\n",
    "cv_risk = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "\n",
    "def _cindex_scorer(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Concordance index scorer for survival models.\n",
    "    Assumes y_true is a structured array with fields ('event', 'time').\n",
    "    Uses negative scores so that higher hazard -> lower survival time.\n",
    "    \"\"\"\n",
    "    return concordance_index_censored(y_true[\"event\"], y_true[\"time\"], -y_pred)[0]\n",
    "\n",
    "\n",
    "scorer_risk = make_scorer(_cindex_scorer, greater_is_better=True, needs_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "423799f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: AUC=0.852\n",
      "svc: AUC=0.875\n",
      "rf: AUC=0.897\n",
      "xgb: AUC=0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import is_classifier, is_regressor\n",
    "\n",
    "\n",
    "# 6) Class models\n",
    "class_results = {}\n",
    "class_table_rows = []\n",
    "# y_class = y_class.astype(int).to_numpy().ravel()\n",
    "\n",
    "for name, (estimator, search_space) in class_models.items():\n",
    "    if name == \"xgb\":\n",
    "        pipe = Pipeline(\n",
    "            [\n",
    "                (\"selector\", selector),\n",
    "                (\"tocupy\", ToCuPy()),\n",
    "                (\"model\", estimator),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pipe = Pipeline(\n",
    "            [\n",
    "                (\"selector\", selector),\n",
    "                (\"model\", estimator),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=search_space,\n",
    "        n_iter=50,\n",
    "        cv=cv_class,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        random_state=0,\n",
    "        refit=True,\n",
    "    )\n",
    "\n",
    "    search.fit(X_class, y_class)\n",
    "    class_results[name] = {\n",
    "        \"best_score\": search.best_score_,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"best_estimator\": search.best_estimator_,\n",
    "    }\n",
    "    print(f\"{name}: AUC={search.best_score_:.3f}\")\n",
    "    if run:\n",
    "        run.log(\n",
    "            {\n",
    "                f\"class/{name}/best_auc\": search.best_score_,\n",
    "                f\"class/{name}/best_params\": json.dumps(search.best_params_, default=str),\n",
    "            }\n",
    "        )\n",
    "        class_table_rows.append([name, search.best_score_, json.dumps(search.best_params_, default=str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38bb71e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg': {'best_score': 0.8522435897435898,\n",
       "  'best_params': {'selector__kbest': 10,\n",
       "   'model__l1_ratio': 0.55,\n",
       "   'model__C': 26.826957952797244},\n",
       "  'best_estimator': Pipeline(steps=[('selector', FCBFSelector(kbest=10, mode='rank')),\n",
       "                  ('model',\n",
       "                   LogisticRegression(C=26.826957952797244, l1_ratio=0.55,\n",
       "                                      max_iter=5000, penalty='elasticnet',\n",
       "                                      solver='saga'))])},\n",
       " 'svc': {'best_score': 0.8749999999999998,\n",
       "  'best_params': {'selector__kbest': 20,\n",
       "   'model__kernel': 'rbf',\n",
       "   'model__gamma': 0.001,\n",
       "   'model__C': 0.01},\n",
       "  'best_estimator': Pipeline(steps=[('selector', FCBFSelector(kbest=20, mode='rank')),\n",
       "                  ('model', SVC(C=0.01, gamma=0.001, probability=True))])},\n",
       " 'rf': {'best_score': 0.8972756410256411,\n",
       "  'best_params': {'selector__kbest': 40,\n",
       "   'model__n_estimators': 200,\n",
       "   'model__min_samples_split': 2,\n",
       "   'model__max_features': 'sqrt',\n",
       "   'model__max_depth': 10},\n",
       "  'best_estimator': Pipeline(steps=[('selector', FCBFSelector(kbest=40, mode='rank')),\n",
       "                  ('model',\n",
       "                   RandomForestClassifier(max_depth=10, n_estimators=200))])},\n",
       " 'xgb': {'best_score': 0.8959935897435898,\n",
       "  'best_params': {'selector__kbest': 20,\n",
       "   'model__subsample': 0.9,\n",
       "   'model__reg_lambda': 0.001,\n",
       "   'model__reg_alpha': 0.03162277660168379,\n",
       "   'model__n_estimators': 600,\n",
       "   'model__max_depth': 3,\n",
       "   'model__learning_rate': 0.03,\n",
       "   'model__gamma': 0,\n",
       "   'model__colsample_bytree': 0.9},\n",
       "  'best_estimator': Pipeline(steps=[('selector', FCBFSelector(kbest=20, mode='rank')),\n",
       "                  ('tocupy', ToCuPy()),\n",
       "                  ('model',\n",
       "                   XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                                 colsample_bytree=0.9, device='cuda',\n",
       "                                 early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric='logloss',\n",
       "                                 feature_types=None, feature_weights=None,\n",
       "                                 gamma=0, grow_policy=None, importance_type=None,\n",
       "                                 interaction_constraints=None, learning_rate=0.03,\n",
       "                                 max_bin=None, max_cat_threshold=None,\n",
       "                                 max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                 max_depth=3, max_leaves=None,\n",
       "                                 min_child_weight=None, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=600, n_jobs=None,\n",
       "                                 num_parallel_tree=None, ...))])}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fd3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_models = make_risk_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dde365e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/juanrafaelvalera@vhio.org/ondemand/CARE/src/preproc/preproc_utils.py\", line 34, in fit\n    selected_idX = fcbf(X, y, mode=self.mode, delta=self.threshold)  # Returns the list with the features ordered by importance\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/function/information_theoretical_based/FCBF.py\", line 45, in fcbf\n    t1[i, 1] = su_calculation(f, y)\n               ^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/mutual_information.py\", line 58, in su_calculation\n    t1 = information_gain(f1, f2)\n         ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/mutual_information.py\", line 18, in information_gain\n    ig = ee.entropyd(f1) - conditional_entropy(f1, f2)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/mutual_information.py\", line 37, in conditional_entropy\n    ce = ee.entropyd(f1) - ee.midd(f1, f2)\n                           ^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/entropy_estimators.py\", line 104, in midd\n    return -entropyd(list(zip(x, y))) + entropyd(x) + entropyd(y)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/entropy_estimators.py\", line 96, in entropyd\n    return entropyfromprobs(hist(sx), base=base)\n                            ^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/entropy_estimators.py\", line 119, in hist\n    d[s] = d.get(s, 0) + 1\n           ^^^^^^^^^^^\nTypeError: unhashable type: 'writeable void-scalar'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Caso 1: sin hiperparámetros -> CV score + fit directo\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (search_space \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(search_space, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(search_space) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 28\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_risk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorer_risk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     pipe\u001b[38;5;241m.\u001b[39mfit(X, y_surv)\n\u001b[1;32m     31\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(scores))\n",
      "File \u001b[0;32m/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:677\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    675\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 677\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:419\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    398\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    399\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    400\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    401\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    417\u001b[0m )\n\u001b[0;32m--> 419\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:505\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    499\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/sklearn/base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/juanrafaelvalera@vhio.org/ondemand/CARE/src/preproc/preproc_utils.py\", line 34, in fit\n    selected_idX = fcbf(X, y, mode=self.mode, delta=self.threshold)  # Returns the list with the features ordered by importance\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/function/information_theoretical_based/FCBF.py\", line 45, in fcbf\n    t1[i, 1] = su_calculation(f, y)\n               ^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/mutual_information.py\", line 58, in su_calculation\n    t1 = information_gain(f1, f2)\n         ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/mutual_information.py\", line 18, in information_gain\n    ig = ee.entropyd(f1) - conditional_entropy(f1, f2)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/mutual_information.py\", line 37, in conditional_entropy\n    ce = ee.entropyd(f1) - ee.midd(f1, f2)\n                           ^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/entropy_estimators.py\", line 104, in midd\n    return -entropyd(list(zip(x, y))) + entropyd(x) + entropyd(y)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/entropy_estimators.py\", line 96, in entropyd\n    return entropyfromprobs(hist(sx), base=base)\n                            ^^^^^^^^\n  File \"/mnt/CCBdata/projects/conda_envs/BC/lib/python3.11/site-packages/skfeature/utility/entropy_estimators.py\", line 119, in hist\n    d[s] = d.get(s, 0) + 1\n           ^^^^^^^^^^^\nTypeError: unhashable type: 'writeable void-scalar'\n"
     ]
    }
   ],
   "source": [
    "from sksurv.util import Surv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# 7) Risk models\n",
    "risk_results = {}\n",
    "risk_table_rows = []\n",
    "y_surv = Surv.from_arrays(event=y_event.astype(bool), time=y_time)\n",
    "\n",
    "for name, (estimator, search_space) in risk_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    if name == \"xgb\":\n",
    "        # Nota: para FCBF NO te aporta CuPy; si lo usas, asegúrate de que selector no reciba CuPy.\n",
    "        pipe = Pipeline([\n",
    "            (\"selector\", selector),\n",
    "            (\"tocupy\", ToCuPy()),\n",
    "            (\"model\", estimator),\n",
    "        ])\n",
    "    else:\n",
    "        pipe = Pipeline([\n",
    "            (\"selector\", selector),\n",
    "            (\"model\", estimator),\n",
    "        ])\n",
    "\n",
    "    # Caso 1: sin hiperparámetros -> CV score + fit directo\n",
    "    if (search_space is None) or (isinstance(search_space, dict) and len(search_space) == 0):\n",
    "        scores = cross_val_score(pipe, X, y_surv, cv=cv_risk, scoring=scorer_risk, n_jobs=-1)\n",
    "        pipe.fit(X, y_surv)\n",
    "\n",
    "        best_score = float(np.mean(scores))\n",
    "        best_params = {}\n",
    "        best_estimator = pipe\n",
    "\n",
    "    # Caso 2: con hiperparámetros -> RandomizedSearchCV\n",
    "    else:\n",
    "        # Caso especial: XGB survival:cox no acepta y_surv (structured)\n",
    "        if name == \"xgb\":\n",
    "            search = RandomizedSearchCV(\n",
    "                pipe,\n",
    "                param_distributions=search_space,\n",
    "                n_iter=5,\n",
    "                cv=cv_risk,\n",
    "                scoring=scorer_risk,\n",
    "                n_jobs=-1,\n",
    "                random_state=0,\n",
    "                refit=True,\n",
    "                error_score=\"raise\",\n",
    "            )\n",
    "            # XGB survival: y = time, weights = event\n",
    "            search.fit(X, y_time.astype(float), model__sample_weight=y_event.astype(float))\n",
    "\n",
    "        else:\n",
    "            search = RandomizedSearchCV(\n",
    "                pipe,\n",
    "                param_distributions=search_space,\n",
    "                n_iter=50,\n",
    "                cv=cv_risk,\n",
    "                scoring=scorer_risk,\n",
    "                n_jobs=-1,\n",
    "                random_state=0,\n",
    "                refit=True,\n",
    "                error_score=\"raise\",\n",
    "            )\n",
    "            search.fit(X, y_surv)\n",
    "\n",
    "        best_score = float(search.best_score_)\n",
    "        best_params = search.best_params_\n",
    "        best_estimator = search.best_estimator_\n",
    "\n",
    "    # Guardar resultados\n",
    "    risk_results[name] = {\n",
    "        \"best_score\": best_score,\n",
    "        \"best_params\": best_params,\n",
    "        \"best_estimator\": best_estimator,\n",
    "    }\n",
    "    print(f\"{name}: C-index={best_score:.3f}\")\n",
    "\n",
    "    if run:\n",
    "        run.log({\n",
    "            f\"risk/{name}/best_cindex\": best_score,\n",
    "            f\"risk/{name}/best_params\": json.dumps(best_params, default=str),\n",
    "        })\n",
    "        risk_table_rows.append([name, best_score, json.dumps(best_params, default=str)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
